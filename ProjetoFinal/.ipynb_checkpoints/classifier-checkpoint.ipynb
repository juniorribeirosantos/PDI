{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import metrics\n",
    "from keras import callbacks\n",
    "import os\n",
    "import cv2\n",
    "import string\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Init main values\n",
    "symbols = string.ascii_lowercase + \"0123456789\" # All symbols captcha can contain\n",
    "num_symbols = len(symbols)\n",
    "img_shape = (50, 200, 1)\n",
    "#print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First we need to preprocess the data\n",
    "def preprocess_data():\n",
    "    n_samples = len(os.listdir('samples'))\n",
    "    X = np.zeros((n_samples, 50, 200, 1))\n",
    "    y = np.zeros((5, n_samples, num_symbols))\n",
    "\n",
    "    for i, pic in enumerate(os.listdir('samples')):\n",
    "        # Read image as grayscale\n",
    "        img = cv2.imread(os.path.join('samples', pic), cv2.IMREAD_GRAYSCALE)\n",
    "        '''if i == 0:\n",
    "            print(img)\n",
    "            #plt.imshow(img, 'gray')\n",
    "         '''   \n",
    "        pic_target = pic[:-4] #tira .jpg\n",
    "        #print(pic_target)\n",
    "        if len(pic_target) < 6:\n",
    "            # Scale and reshape image\n",
    "            img = img / 255. #conteÃºdo de 0 a 1\n",
    "            img = np.reshape(img, (50, 200, 1)) #muda formato do array\n",
    "            #if i == 0:\n",
    "            #    print(img)\n",
    "            #    plt.imshow(img, 'gray')\n",
    "            \n",
    "            \n",
    "            # Define targets and code them using OneHotEncoding\n",
    "            targs = np.zeros((5, num_symbols))\n",
    "            for j, l in enumerate(pic_target):\n",
    "                ind = symbols.find(l)\n",
    "                targs[j, ind] = 1\n",
    "            X[i] = img\n",
    "            y[:, i] = targs\n",
    "        #else: #talvez remover esse doido diferente\n",
    "            #print(pic_target)\n",
    "    \n",
    "    # Return final data\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data()\n",
    "X_train, y_train = X[:970], y[:, :970]\n",
    "X_test, y_test = X[970:], y[:, 970:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function that creates a net\n",
    "def create_net():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    model = Model(img, outs)\n",
    "    model.compile('rmsprop', loss=['categorical_crossentropy', 'categorical_crossentropy',\n",
    "                                   'categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 19s 24ms/step - loss: 17.4706 - dense_2_loss: 3.3932 - dense_4_loss: 3.5179 - dense_6_loss: 3.4604 - dense_8_loss: 3.5756 - dense_10_loss: 3.5235 - val_loss: 17.0424 - val_dense_2_loss: 3.4479 - val_dense_4_loss: 3.3515 - val_dense_6_loss: 3.3660 - val_dense_8_loss: 3.4781 - val_dense_10_loss: 3.3989\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 19s 24ms/step - loss: 15.6728 - dense_2_loss: 2.9927 - dense_4_loss: 3.0844 - dense_6_loss: 3.1697 - dense_8_loss: 3.2205 - dense_10_loss: 3.2055 - val_loss: 14.8163 - val_dense_2_loss: 2.7069 - val_dense_4_loss: 2.8542 - val_dense_6_loss: 3.0159 - val_dense_8_loss: 3.0756 - val_dense_10_loss: 3.1638\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 14.2873 - dense_2_loss: 2.6193 - dense_4_loss: 2.7762 - dense_6_loss: 2.9474 - dense_8_loss: 2.9737 - dense_10_loss: 2.9707 - val_loss: 14.6553 - val_dense_2_loss: 2.6826 - val_dense_4_loss: 2.7040 - val_dense_6_loss: 3.2291 - val_dense_8_loss: 3.0491 - val_dense_10_loss: 2.9905\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 12.8999 - dense_2_loss: 2.2657 - dense_4_loss: 2.4852 - dense_6_loss: 2.7420 - dense_8_loss: 2.6953 - dense_10_loss: 2.7118 - val_loss: 11.5261 - val_dense_2_loss: 1.9475 - val_dense_4_loss: 2.1283 - val_dense_6_loss: 2.4703 - val_dense_8_loss: 2.5086 - val_dense_10_loss: 2.4714\n",
      "Epoch 5/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 11.3116 - dense_2_loss: 1.8299 - dense_4_loss: 2.1757 - dense_6_loss: 2.4371 - dense_8_loss: 2.4125 - dense_10_loss: 2.4563 - val_loss: 9.2801 - val_dense_2_loss: 0.9628 - val_dense_4_loss: 1.6453 - val_dense_6_loss: 2.3734 - val_dense_8_loss: 2.1789 - val_dense_10_loss: 2.1197\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 9.6263 - dense_2_loss: 1.4468 - dense_4_loss: 1.7532 - dense_6_loss: 2.0660 - dense_8_loss: 2.1497 - dense_10_loss: 2.2106 - val_loss: 7.3213 - val_dense_2_loss: 0.7868 - val_dense_4_loss: 1.6238 - val_dense_6_loss: 1.4643 - val_dense_8_loss: 1.6694 - val_dense_10_loss: 1.7769\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 7.9888 - dense_2_loss: 1.1118 - dense_4_loss: 1.4348 - dense_6_loss: 1.7329 - dense_8_loss: 1.8573 - dense_10_loss: 1.8518 - val_loss: 6.6249 - val_dense_2_loss: 0.4667 - val_dense_4_loss: 1.2323 - val_dense_6_loss: 1.6301 - val_dense_8_loss: 1.7045 - val_dense_10_loss: 1.5912\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 6.5523 - dense_2_loss: 0.8777 - dense_4_loss: 1.1415 - dense_6_loss: 1.4304 - dense_8_loss: 1.4787 - dense_10_loss: 1.6240 - val_loss: 5.6735 - val_dense_2_loss: 0.4973 - val_dense_4_loss: 0.9694 - val_dense_6_loss: 1.2838 - val_dense_8_loss: 1.5831 - val_dense_10_loss: 1.3400\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 5.2408 - dense_2_loss: 0.6922 - dense_4_loss: 0.8923 - dense_6_loss: 1.1828 - dense_8_loss: 1.1780 - dense_10_loss: 1.2954 - val_loss: 4.6003 - val_dense_2_loss: 0.2187 - val_dense_4_loss: 0.9118 - val_dense_6_loss: 0.9352 - val_dense_8_loss: 1.0144 - val_dense_10_loss: 1.5201\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 4.1771 - dense_2_loss: 0.4915 - dense_4_loss: 0.6906 - dense_6_loss: 0.9603 - dense_8_loss: 1.0082 - dense_10_loss: 1.0265 - val_loss: 3.9816 - val_dense_2_loss: 0.2293 - val_dense_4_loss: 0.5817 - val_dense_6_loss: 0.9122 - val_dense_8_loss: 1.1806 - val_dense_10_loss: 1.0778\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 3.6119 - dense_2_loss: 0.4374 - dense_4_loss: 0.5709 - dense_6_loss: 0.8234 - dense_8_loss: 0.8787 - dense_10_loss: 0.9016 - val_loss: 3.3747 - val_dense_2_loss: 0.0975 - val_dense_4_loss: 0.4872 - val_dense_6_loss: 1.0373 - val_dense_8_loss: 0.7987 - val_dense_10_loss: 0.9541\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 2.8581 - dense_2_loss: 0.2943 - dense_4_loss: 0.4603 - dense_6_loss: 0.6359 - dense_8_loss: 0.7358 - dense_10_loss: 0.7318 - val_loss: 3.2882 - val_dense_2_loss: 0.1650 - val_dense_4_loss: 0.5108 - val_dense_6_loss: 1.0136 - val_dense_8_loss: 0.5966 - val_dense_10_loss: 1.0022\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 2.4309 - dense_2_loss: 0.2441 - dense_4_loss: 0.3907 - dense_6_loss: 0.5533 - dense_8_loss: 0.6519 - dense_10_loss: 0.5909 - val_loss: 3.7448 - val_dense_2_loss: 0.1327 - val_dense_4_loss: 0.5623 - val_dense_6_loss: 0.9165 - val_dense_8_loss: 1.0968 - val_dense_10_loss: 1.0364\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 2.0676 - dense_2_loss: 0.2446 - dense_4_loss: 0.3045 - dense_6_loss: 0.4721 - dense_8_loss: 0.5625 - dense_10_loss: 0.4839 - val_loss: 3.0707 - val_dense_2_loss: 0.0465 - val_dense_4_loss: 0.4306 - val_dense_6_loss: 0.9590 - val_dense_8_loss: 0.7679 - val_dense_10_loss: 0.8667\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 1.7378 - dense_2_loss: 0.2002 - dense_4_loss: 0.2647 - dense_6_loss: 0.4132 - dense_8_loss: 0.4668 - dense_10_loss: 0.3928 - val_loss: 2.8976 - val_dense_2_loss: 0.0359 - val_dense_4_loss: 0.4345 - val_dense_6_loss: 0.8320 - val_dense_8_loss: 0.7563 - val_dense_10_loss: 0.8388\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 1.4591 - dense_2_loss: 0.1520 - dense_4_loss: 0.2394 - dense_6_loss: 0.3838 - dense_8_loss: 0.3582 - dense_10_loss: 0.3257 - val_loss: 3.4396 - val_dense_2_loss: 0.0373 - val_dense_4_loss: 0.5607 - val_dense_6_loss: 0.8399 - val_dense_8_loss: 0.7231 - val_dense_10_loss: 1.2786\n",
      "Epoch 17/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 1.3810 - dense_2_loss: 0.1569 - dense_4_loss: 0.2212 - dense_6_loss: 0.3310 - dense_8_loss: 0.3432 - dense_10_loss: 0.3287 - val_loss: 2.8321 - val_dense_2_loss: 0.0272 - val_dense_4_loss: 0.4091 - val_dense_6_loss: 0.8239 - val_dense_8_loss: 0.6637 - val_dense_10_loss: 0.9081\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 1.2185 - dense_2_loss: 0.1338 - dense_4_loss: 0.2002 - dense_6_loss: 0.3121 - dense_8_loss: 0.2920 - dense_10_loss: 0.2803 - val_loss: 2.8913 - val_dense_2_loss: 0.0489 - val_dense_4_loss: 0.4418 - val_dense_6_loss: 0.8505 - val_dense_8_loss: 0.7173 - val_dense_10_loss: 0.8328\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 1.0702 - dense_2_loss: 0.1069 - dense_4_loss: 0.1505 - dense_6_loss: 0.2679 - dense_8_loss: 0.2707 - dense_10_loss: 0.2741 - val_loss: 2.5077 - val_dense_2_loss: 0.0763 - val_dense_4_loss: 0.3958 - val_dense_6_loss: 0.7605 - val_dense_8_loss: 0.5832 - val_dense_10_loss: 0.6919\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.9507 - dense_2_loss: 0.1382 - dense_4_loss: 0.1453 - dense_6_loss: 0.2415 - dense_8_loss: 0.2052 - dense_10_loss: 0.2204 - val_loss: 2.6940 - val_dense_2_loss: 0.0667 - val_dense_4_loss: 0.3894 - val_dense_6_loss: 0.8394 - val_dense_8_loss: 0.6338 - val_dense_10_loss: 0.7646\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.8910 - dense_2_loss: 0.0978 - dense_4_loss: 0.1579 - dense_6_loss: 0.2197 - dense_8_loss: 0.2053 - dense_10_loss: 0.2103 - val_loss: 2.6948 - val_dense_2_loss: 0.0248 - val_dense_4_loss: 0.3937 - val_dense_6_loss: 0.8435 - val_dense_8_loss: 0.5927 - val_dense_10_loss: 0.8402\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.8118 - dense_2_loss: 0.1103 - dense_4_loss: 0.1387 - dense_6_loss: 0.1901 - dense_8_loss: 0.1993 - dense_10_loss: 0.1735 - val_loss: 2.8117 - val_dense_2_loss: 0.0810 - val_dense_4_loss: 0.4628 - val_dense_6_loss: 0.8887 - val_dense_8_loss: 0.6200 - val_dense_10_loss: 0.7592\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.7008 - dense_2_loss: 0.0863 - dense_4_loss: 0.1172 - dense_6_loss: 0.1427 - dense_8_loss: 0.1906 - dense_10_loss: 0.1640 - val_loss: 3.0630 - val_dense_2_loss: 0.0181 - val_dense_4_loss: 0.4000 - val_dense_6_loss: 0.8152 - val_dense_8_loss: 0.8276 - val_dense_10_loss: 1.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.7319 - dense_2_loss: 0.0711 - dense_4_loss: 0.1116 - dense_6_loss: 0.1913 - dense_8_loss: 0.1815 - dense_10_loss: 0.1763 - val_loss: 2.4335 - val_dense_2_loss: 0.0674 - val_dense_4_loss: 0.3264 - val_dense_6_loss: 0.7026 - val_dense_8_loss: 0.6034 - val_dense_10_loss: 0.7336\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6085 - dense_2_loss: 0.0888 - dense_4_loss: 0.1110 - dense_6_loss: 0.1385 - dense_8_loss: 0.1611 - dense_10_loss: 0.1091 - val_loss: 3.1573 - val_dense_2_loss: 0.0072 - val_dense_4_loss: 0.4075 - val_dense_6_loss: 0.9080 - val_dense_8_loss: 0.9123 - val_dense_10_loss: 0.9223\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6253 - dense_2_loss: 0.0622 - dense_4_loss: 0.0927 - dense_6_loss: 0.1483 - dense_8_loss: 0.1559 - dense_10_loss: 0.1661 - val_loss: 3.1618 - val_dense_2_loss: 0.0070 - val_dense_4_loss: 0.3737 - val_dense_6_loss: 0.9121 - val_dense_8_loss: 0.9831 - val_dense_10_loss: 0.8860\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.5286 - dense_2_loss: 0.0427 - dense_4_loss: 0.0664 - dense_6_loss: 0.1378 - dense_8_loss: 0.1479 - dense_10_loss: 0.1339 - val_loss: 3.0261 - val_dense_2_loss: 0.0132 - val_dense_4_loss: 0.3856 - val_dense_6_loss: 0.8933 - val_dense_8_loss: 0.7404 - val_dense_10_loss: 0.9937\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.5691 - dense_2_loss: 0.0624 - dense_4_loss: 0.0811 - dense_6_loss: 0.1453 - dense_8_loss: 0.1577 - dense_10_loss: 0.1224 - val_loss: 2.8804 - val_dense_2_loss: 0.0189 - val_dense_4_loss: 0.3909 - val_dense_6_loss: 0.9341 - val_dense_8_loss: 0.8258 - val_dense_10_loss: 0.7106\n",
      "Epoch 29/30\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.5682 - dense_2_loss: 0.0489 - dense_4_loss: 0.0681 - dense_6_loss: 0.1338 - dense_8_loss: 0.1829 - dense_10_loss: 0.1344 - val_loss: 2.9991 - val_dense_2_loss: 0.0488 - val_dense_4_loss: 0.3756 - val_dense_6_loss: 0.8676 - val_dense_8_loss: 0.8258 - val_dense_10_loss: 0.8813\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.4235 - dense_2_loss: 0.0701 - dense_4_loss: 0.0777 - dense_6_loss: 0.0926 - dense_8_loss: 0.1091 - dense_10_loss: 0.0740 - val_loss: 2.7035 - val_dense_2_loss: 0.1035 - val_dense_4_loss: 0.3604 - val_dense_6_loss: 0.7398 - val_dense_8_loss: 0.8968 - val_dense_10_loss: 0.6031\n"
     ]
    }
   ],
   "source": [
    "net = create_net()\n",
    "history = net.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], \n",
    "                  batch_size=32, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE) / 255.\n",
    "    res = np.array(net.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (5, 36))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    for l in l_ind:\n",
    "        capt += symbols[l]\n",
    "        \n",
    "    return capt, sum(probs) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \n",
    "    total = len(y_pred)\n",
    "    rigth = 0\n",
    "    \n",
    "    for i in range(0, total):\n",
    "        \n",
    "        if y_pred[i] == y_true[i]:\n",
    "            rigth += 1\n",
    "            print('pred: ' + y_pred[i] + ' true: '+ y_true[i])\n",
    "            \n",
    "    perc = rigth/total\n",
    "    \n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 67dey true: 67dey\n",
      "pred: 7e2y7 true: 7e2y7\n",
      "pred: bny4w true: bny4w\n",
      "pred: de45x true: de45x\n",
      "pred: dnne7 true: dnne7\n",
      "pred: gxx2p true: gxx2p\n",
      "pred: pdcp4 true: pdcp4\n",
      "pred: mcyfx true: mcyfx\n",
      "pred: bm3p8 true: bm3p8\n",
      "pred: f83pn true: f83pn\n",
      "pred: 6c3n6 true: 6c3n6\n",
      "pred: 5yxgp true: 5yxgp\n",
      "pred: 7dwx4 true: 7dwx4\n",
      "pred: 2bg48 true: 2bg48\n",
      "pred: c2g4d true: c2g4d\n",
      "pred: 25egp true: 25egp\n",
      "pred: d7c5x true: d7c5x\n",
      "pred: fg8n4 true: fg8n4\n",
      "pred: mg5nn true: mg5nn\n",
      "pred: e46pd true: e46pd\n",
      "pred: 8cccc true: 8cccc\n",
      "pred: m448b true: m448b\n",
      "pred: 6c3p5 true: 6c3p5\n",
      "pred: nd5wg true: nd5wg\n",
      "pred: 7cgym true: 7cgym\n",
      "pred: myc3c true: myc3c\n",
      "pred: 8w875 true: 8w875\n",
      "pred: xw465 true: xw465\n",
      "pred: 85dxn true: 85dxn\n",
      "pred: c4bgd true: c4bgd\n",
      "pred: dw6mn true: dw6mn\n",
      "pred: y866y true: y866y\n",
      "pred: 77wp4 true: 77wp4\n",
      "pred: pdw38 true: pdw38\n",
      "pred: bgb48 true: bgb48\n",
      "pred: pn7pn true: pn7pn\n",
      "pred: x4gg5 true: x4gg5\n",
      "pred: p2dw7 true: p2dw7\n",
      "pred: gy433 true: gy433\n",
      "pred: yd38e true: yd38e\n",
      "pred: 7gce6 true: 7gce6\n",
      "pred: pcmcc true: pcmcc\n",
      "pred: 8y6b3 true: 8y6b3\n",
      "pred: 6ydyp true: 6ydyp\n",
      "pred: 7m8px true: 7m8px\n",
      "pred: 22d5n true: 22d5n\n",
      "pred: nw5b2 true: nw5b2\n",
      "pred: neggn true: neggn\n",
      "pred: n3x4c true: n3x4c\n",
      "pred: 368y5 true: 368y5\n",
      "pred: c753e true: c753e\n",
      "pred: dce8y true: dce8y\n",
      "pred: 7yf62 true: 7yf62\n",
      "0.5353535353535354\n"
     ]
    }
   ],
   "source": [
    "l = os.listdir('samples')[970:]\n",
    "#l\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for ele in l:\n",
    "    y_target = ele[:-4]\n",
    "    \n",
    "    if len(y_target) < 6: #evita esse arquivo: samples/.ipynb_checkpoints <class 'NoneType'>\n",
    "    \n",
    "        y_true.append(y_target) \n",
    "        #print(ele)\n",
    "\n",
    "        pred, prob = predict('samples/'+ele)\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "        #print(pred, prob)\n",
    "        \n",
    "print(accuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step\n",
      "[2.297804145812988, 0.07645923763513565, 0.22826772689819336, 0.5593409895896911, 0.9303092360496521, 0.5034270751476287]\n",
      "('8n5p3', 0.7455646336078644)\n",
      "('f2m8n', 0.8912076950073242)\n",
      "('dce8y', 0.6056237548589707)\n",
      "('3eny7', 0.8647225975990296)\n",
      "('npxb7', 0.8897377252578735)\n",
      "('573nn', 0.693441379070282)\n",
      "('bm3p8', 0.5520117878913879)\n"
     ]
    }
   ],
   "source": [
    "# Check model on some samples\n",
    "print(net.evaluate(X_test, [y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]]))\n",
    "\n",
    "print(predict('samples/8n5p3.png'))\n",
    "print(predict('samples/f2m8n.png'))\n",
    "print(predict('samples/dce8y.png'))\n",
    "print(predict('samples/3eny7.png'))\n",
    "print(predict('samples/npxb7.png'))\n",
    "\n",
    "####outros\n",
    "print(predict('samples/573bn.png'))\n",
    "print(predict('samples/bm3p8.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
